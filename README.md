# LLM Context Generator Streamlit App

## Overview

This Streamlit application provides a user-friendly interface to aggregate content from various source files (including PDFs, plain text, Markdown, and source code) into a single, structured context file suitable for Large Language Models (LLMs). It leverages the capabilities of two external command-line tools:

1.  **`llama-parse`**: Used to extract text content from PDF documents into Markdown format. This process utilizes the LlamaCloud API.
2.  **`files-to-prompt`**: Used to gather text-based files from specified directories and format the combined content.

The primary goal is to simplify the preparation of large, diverse context sets (like code repositories, documentation folders, research papers) that often exceed the direct input limits or require specific formatting for optimal LLM performance. The application outputs a single text file where each source file's content is wrapped in Claude XML-style `<document>` tags, as generated by `files-to-prompt` using the `--cxml` flag.

**Key Workflow Distinction:**

* **PDF Parsing (`llama-parse`)**: Requires an internet connection and relies on the LlamaCloud service. It requires a **one-time manual authentication** step (`llama-parse auth`) performed in your terminal to link the tool to your LlamaCloud API key. This app checks for this authentication but **does not store or handle your API key directly**.
* **File Combination (`files-to-prompt`)**: Operates locally, scanning directories recursively and formatting the output.

## Features

* **Multi-Source Processing**: Handles both PDF documents and various text-based files (`.txt`, `.md`, `.py`, `.js`, `.json`, `.xml`, etc.).
* **PDF Parsing Integration**: Uses `llama-parse` to convert PDF content to Markdown, making it usable alongside text files. Parsed PDFs are stored in a configurable sub-directory.
* **LlamaParse Authentication Check**: Verifies if the necessary `llama-parse auth` step has been completed before attempting PDF parsing, guiding the user if needed.
* **Flexible Processing Modes**:
    * **Both**: Parses selected PDFs and combines them (recursively) with all text files in the specified TXT directory.
    * **PDF only**: Parses selected PDFs and combines *only* the resulting Markdown files from the parsed PDF sub-directory.
    * **TXT only**: Skips PDF parsing, clears any previous parsed PDF results, and combines *only* the text files found recursively in the specified TXT directory (excluding the cleared parsed PDF sub-directory).
* **File Management UI**:
    * Tabs for uploading new PDF and Plaintext files directly to the configured input directories.
    * Lists existing files in input directories.
    * Provides options to delete individual files from input directories directly within the UI.
* **Configurable Paths**: Use the sidebar to easily set:
    * Input directory for PDFs (`PDF Input Folder`).
    * Input directory for text files (`TXT Input Folder`). This directory also hosts the sub-directory for parsed PDFs.
    * Output filename (`Output Context Filename`).
    * Output location (`Output File Location`).
    * *Absolute paths are recommended for clarity.*
* **Structured Output Format**: Generates a single context file using Claude XML tags (`<document path="...">...</document>`) via `files-to-prompt --cxml`.
* **In-App Preview**: Displays the beginning or entirety (depending on size) of the generated context file for immediate review.
* **Status & Error Feedback**: Provides messages, progress bars (for parsing), and toasts to inform the user about the process and any issues encountered.

## Prerequisites (Linux Host Recommended)

This guide assumes a Linux-based environment (like Ubuntu, Debian, CentOS, WSL). Adjust commands for macOS or Windows if necessary.

1.  **Python**: Version 3.8 or later recommended.
    * Check: `python3 --version`
2.  **pip**: Python package installer (usually included with Python).
    * Check: `pip3 --version` or `python3 -m pip --version`
3.  **Node.js & npm**: Required *only* for installing the `llama-parse-cli` tool globally.
    * Check: `node -v` and `npm -v`
    * Install if missing (example using `apt` on Debian/Ubuntu):
        ```bash
        sudo apt update && sudo apt install nodejs npm -y
        ```
    * For other distributions or methods (like NVM), refer to Node.js installation guides.
4.  **LlamaCloud Account & API Key**: Needed *only* for the one-time manual `llama-parse auth` setup in your terminal. This is **not** used directly by the Streamlit app.
    * Sign up and generate an API key at [LlamaCloud](https://cloud.llamaindex.ai/). The key typically starts with `llx-`.

## Setup Instructions (Linux Host)

1.  **Get the Code:**
    * Save the Streamlit Python script provided (e.g., name it `context_generator_app.py`) into a dedicated directory.
    * Navigate to that directory in your terminal:
        ```bash
        mkdir ~/streamlit-context-gen && cd ~/streamlit-context-gen
        # (Save the script here as context_generator_app.py)
        ```

2.  **Create Virtual Environment (Recommended):**
    * Isolates Python dependencies for this project.
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```
    * You'll need to run `source venv/bin/activate` each time you open a new terminal to work on this project.

3.  **Install Python Dependencies:**
    * Install Streamlit (UI framework) and `files-to-prompt` (file combination tool):
        ```bash
        pip install streamlit files-to-prompt
        ```

4.  **Install `llama-parse` CLI Tool:**
    * Install the command-line interface for `llama-parse` globally using npm:
        ```bash
        npm install -g llama-parse-cli
        ```
    * The `-g` flag installs it system-wide (or user-wide depending on npm setup). You might need `sudo` if you encounter permission errors, or configure npm for global installs without sudo.
    * Verify the installation:
        ```bash
        llama-parse --version
        ```
    * If the command isn't found after installation, ensure the npm global bin directory is in your system's `PATH`. You might need to restart your terminal or shell session.

5.  **Authenticate `llama-parse` (CRITICAL ONE-TIME STEP):**
    * This step securely stores your LlamaCloud API key locally for the `llama-parse` *command-line tool* to use. The Streamlit app **does not** access the key directly but relies on the tool being pre-authenticated.
    * **Run this command manually in your terminal:**
        ```bash
        llama-parse auth
        ```
    * The tool will prompt you to enter your LlamaCloud API key (the one starting with `llx-`). Paste it in and press Enter.
    * This creates a configuration file, typically at `~/.llama-parse/config.json`, containing your authenticated key. The Streamlit app simply checks for the existence of this file.

## Usage Guide

1.  **Prepare Input Folders:**
    * Create directories where you will place your source files. By default, the app looks for:
        * `pdfs_to_parse` (for your PDF documents)
        * `txt_files` (for your `.txt`, `.md`, `.py`, etc. files)
    * You can change these paths in the app's sidebar. Populate these folders with your files.

2.  **Run the Streamlit App:**
    * Open your terminal, navigate to the directory containing `context_generator_app.py`.
    * Activate the virtual environment (if you created one): `source venv/bin/activate`
    * Launch the app:
        ```bash
        streamlit run context_generator_app.py
        ```
    * Streamlit will provide a local URL (usually `http://localhost:8501`) to open in your web browser.

3.  **Configure Settings (Sidebar):**
    * Use the sidebar on the left to configure input and output paths.
    * **PDF Input Folder**: Path to your PDF files.
    * **TXT Input Folder**: Path to your text-based files. The `parsed_pdfs_streamlit` subfolder will be created inside this directory.
    * **Output Context Filename**: Desired name for the final combined file (default: `context_prompt_output.txt`).
    * **Output File Location**: Directory where the final file will be saved (default: `.`, the directory where you ran the `streamlit run` command).
    * *It's generally best to use absolute paths in these fields for reliability.*

4.  **Manage Files (Optional - Tabs 2 & 3):**
    * Use the "PDF Upload" and "Plaintext Upload" tabs to:
        * View files currently detected in the respective input folders.
        * Upload new files directly through the browser.
        * Delete existing files (use the üóëÔ∏è icon).
    * Click the "Refresh" button if the file list doesn't update automatically after an action (like manual file system changes).

5.  **Select Processing Mode (Tab 1):**
    * Go to the "Process Files" tab.
    * Choose one of the options:
        * `TXT only`: Ignores PDF folder, clears old parsed results, combines files recursively from TXT Input Folder.
        * `PDF only`: Parses PDFs, combines *only* the results from the parsed PDF subfolder.
        * `Both`: Parses PDFs, combines files recursively from the TXT Input Folder (which includes the newly parsed PDFs in the subfolder).

6.  **Generate Context:**
    * Click the "Generate Context File" button.
    * The app will:
        * Check `llama-parse` authentication if PDFs are involved.
        * Parse PDFs if required (showing progress). This uses the LlamaCloud API and requires internet.
        * Determine the correct directory/directories based on the selected mode.
        * Clear the parsed PDF directory if "TXT only" was selected.
        * Run `files-to-prompt` on the target directory/directories.
        * Display status messages and results.

7.  **Review Output:**
    * If successful, a success message will indicate the path to the generated file (`context_prompt_output.txt` by default).
    * An in-app preview ("Output Preview") will show the content of the generated file (formatted with `<document>` tags).
    * You can find the actual output file in the location specified in the "Output File Location" setting.

## Troubleshooting

* **Error: `LlamaParse Not Authenticated: ... config.json ... not found`**:
    * This is the most common issue for PDF parsing. You **must** run `llama-parse auth` manually in your terminal *once* before using the PDF features of this app. See Setup Step 5.
    * Verify the file `~/.llama-parse/config.json` exists after running the command.
* **Error: `'llama-parse'/'files-to-prompt' command not found`**:
    * Ensure both tools were installed correctly (`npm install -g llama-parse-cli` and `pip install files-to-prompt`).
    * Confirm that the locations where these tools were installed are included in your system's `PATH` environment variable. Global npm packages sometimes require PATH adjustments.
    * Try restarting your terminal or shell session after installation.
    * Verify installations with `llama-parse --version` and `files-to-prompt --version`.
* **PDF Parsing Failures/Errors (after successful auth):**
    * Check your internet connection (required for `llama-parse`).
    * Verify your LlamaCloud API key is still valid and active.
    * Check the [LlamaCloud status page](https://status.llamaindex.ai/) (if available) for outages.
    * Look at the specific error messages provided in the Streamlit app's "Output/Error" expanders under the parsing steps.
    * The PDF might be too complex, large, corrupted, or password-protected. Try a simpler PDF.
    * Consult the `llama-parse-cli` documentation or GitHub repository for known issues.
* **Permission Errors (Reading Files or Writing Output):**
    * Ensure the user account running the `streamlit run` command has read permissions for all input directories and files.
    * Ensure the user has write permissions for the specified "Output File Location" and the "TXT Input Folder" (as the parsed PDF subfolder is created within it).
    * If running in Docker or a restricted environment, check volume mounts and container permissions.
* **Blank Input Fields on Load:** Ensure you are using the latest version of the script where the `value=st.session_state.key` argument is correctly included in the `st.text_input` calls in the sidebar. Refresh your browser page (Ctrl+F5 or Cmd+Shift+R).
* **App Resets to First Tab:** This can sometimes happen with `st.rerun`. Using the dedicated "Refresh" buttons should generally keep you on the correct tab. If deletion consistently resets the tab, it might be a limitation of how `st.tabs` interacts with `st.rerun`.

## How it Works

1.  **Configuration**: The user sets input/output paths via the Streamlit sidebar, which are stored in `st.session_state`.
2.  **File Management**: The upload tabs use `st.file_uploader` and `pathlib`/`shutil` to add/remove files from the configured input directories.
3.  **Processing Trigger**: Clicking "Generate Context File" starts the main logic based on the selected mode (`TXT only`, `PDF only`, `Both`).
4.  **PDF Parsing (`llama-parse`)**: If required, the app iterates through PDFs in the `PDF Input Folder`. For each PDF, it calls the `llama-parse parse ...` command as a subprocess. `llama-parse` sends the PDF to the LlamaCloud API, receives the extracted Markdown, and saves it to the designated `parsed_pdfs_streamlit` subfolder (within the `TXT Input Folder`). This subfolder is cleared before parsing begins.
5.  **Directory Selection**: Based on the processing mode and the success of parsing, the app determines the correct *single* directory to pass to `files-to-prompt`:
    * `Both`: The parent `TXT Input Folder`.
    * `PDF only`: The `parsed_pdfs_streamlit` subfolder.
    * `TXT only`: The parent `TXT Input Folder` (after the `parsed_pdfs_streamlit` subfolder is cleared).
6.  **Combination (`files-to-prompt`)**: The app calls the `files-to-prompt <directory> --cxml -o <output_file>` command as a subprocess. `files-to-prompt` recursively scans the specified directory, reads supported text files, and writes their content, wrapped in `<document>` tags, to the final output file.
7.  **Output & Preview**: The final file path is reported, and its content is read and displayed in the Streamlit UI using `st.code`.

## Dependencies

* **`streamlit`**: (Python - via `pip`) The web application framework.
* **`files-to-prompt`**: (Python - via `pip`) Tool for recursively gathering and formatting files.
* **`llama-parse-cli`**: (Node.js - via `npm install -g`) Command-line tool to interact with the LlamaParse API for PDF processing. Requires manual `llama-parse auth`.

## Limitations

* PDF parsing quality and speed depend entirely on the external `llama-parse` tool and LlamaCloud service. Internet access is required for parsing.
* The app does not handle API keys directly; `llama-parse auth` must be done manually beforehand.
* Large numbers of files or very large individual files might strain system resources or exceed `files-to-prompt` or LLM context window limits (though `files-to-prompt` itself handles large content efficiently).
* `files-to-prompt` might encounter issues with files not encoded in UTF-8.
* Error handling for the external CLI tools depends on capturing their standard output/error streams.